{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шаг 0: Описание задачи\n",
    "\"\"\"\n",
    "Задача: Предсказать, будет ли бронирование отеля отменено (is_canceled = 1) или нет (is_canceled = 0)\n",
    "\n",
    "Это задача бинарной классификации, где мы пытаемся предсказать вероятность отмены бронирования\n",
    "на основе различных характеристик бронирования и гостя.\n",
    "\n",
    "Практическая значимость: Помочь отелям оптимизировать управление бронированиями,\n",
    "улучшить прогнозирование загрузки и минимизировать финансовые потери от отмен.\n",
    "\"\"\"\n",
    "\n",
    "# Шаг 1: Импорт библиотек и чтение данных\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ШАГ 1: ИМПОРТ БИБЛИОТЕК И ЧТЕНИЕ ДАННЫХ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Чтение данных\n",
    "df = pd.read_csv('hotel_bookings.csv')\n",
    "\n",
    "# Удаление колонок с утечкой данных\n",
    "leakage_columns = [\n",
    "    'reservation_status', 'reservation_status_date',\n",
    "    'assigned_room_type', 'days_in_waiting_list'\n",
    "]\n",
    "\n",
    "print(\"Колонки с утечкой данных, которые будут удалены:\")\n",
    "for col in leakage_columns:\n",
    "    if col in df.columns:\n",
    "        print(f\"УДАЛЕНО: {col}\")\n",
    "\n",
    "df_clean = df.drop(columns=leakage_columns, errors='ignore')\n",
    "print(f\"Размер датасета до очистки: {df.shape}\")\n",
    "print(f\"Размер датасета после очистки: {df_clean.shape}\")\n",
    "\n",
    "# Шаг 2: Разведочный анализ данных (EDA)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ШАГ 2: РАЗВЕДОЧНЫЙ АНАЛИЗ ДАННЫХ (EDA)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"=== ОСНОВНАЯ ИНФОРМАЦИЯ О ДАННЫХ ===\")\n",
    "print(f\"Размер датасета: {df_clean.shape}\")\n",
    "print(\"\\nПервые 5 строк:\")\n",
    "print(df_clean.head())\n",
    "\n",
    "print(\"\\nИнформация о типах данных:\")\n",
    "print(df_clean.info())\n",
    "\n",
    "print(\"\\nОписательная статистика числовых признаков:\")\n",
    "print(df_clean.describe())\n",
    "\n",
    "print(\"\\nПроверка целевой переменной:\")\n",
    "print(df_clean['is_canceled'].value_counts())\n",
    "print(f\"Доля отмененных бронирований: {df_clean['is_canceled'].mean():.2%}\")\n",
    "\n",
    "# Визуализация распределения целевой переменной\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "df_clean['is_canceled'].value_counts().plot(kind='bar')\n",
    "plt.title('Распределение целевой переменной (is_canceled)')\n",
    "plt.xlabel('Отменено')\n",
    "plt.ylabel('Количество')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df_clean['hotel'].value_counts().plot(kind='bar')\n",
    "plt.title('Распределение по типам отелей')\n",
    "plt.xlabel('Тип отеля')\n",
    "plt.ylabel('Количество')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Визуализация числовых признаков\n",
    "numerical_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Графики распределения (плотность вероятности)\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i, col in enumerate(numerical_cols[:9], 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.kdeplot(data=df_clean, x=col, fill=True, alpha=0.7)\n",
    "    plt.title(f'Распределение {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Плотность')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplot для выявления выбросов\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i, col in enumerate(numerical_cols[:9], 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    sns.boxplot(data=df_clean, y=col)\n",
    "    plt.title(f'Boxplot {col}')\n",
    "    plt.ylabel(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Полная матрица корреляции\n",
    "print(\"\\n=== ПОЛНАЯ МАТРИЦА КОРРЕЛЯЦИИ ===\")\n",
    "\n",
    "# Создаем копию для корреляционного анализа\n",
    "df_corr = df_clean.copy()\n",
    "categorical_cols_corr = df_corr.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Быстрое кодирование для корреляционного анализа\n",
    "for col in categorical_cols_corr:\n",
    "    if df_corr[col].nunique() <= 10:\n",
    "        dummies = pd.get_dummies(df_corr[col], prefix=col)\n",
    "        df_corr = pd.concat([df_corr, dummies], axis=1)\n",
    "        df_corr = df_corr.drop(col, axis=1)\n",
    "    else:\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        le = LabelEncoder()\n",
    "        df_corr[col] = le.fit_transform(df_corr[col].astype(str))\n",
    "\n",
    "# Вычисляем полную матрицу корреляции\n",
    "full_correlation_matrix = df_corr.corr()\n",
    "\n",
    "# Визуализация полной матрицы корреляции\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(full_correlation_matrix, \n",
    "            annot=False,\n",
    "            cmap='coolwarm', \n",
    "            center=0,\n",
    "            square=True,\n",
    "            cbar_kws={\"shrink\": .8})\n",
    "plt.title('Полная матрица корреляции всех признаков', fontsize=16, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Детальная визуализация корреляции с целевой переменной\n",
    "plt.figure(figsize=(12, 10))\n",
    "target_correlation = full_correlation_matrix[['is_canceled']].sort_values('is_canceled', ascending=False)\n",
    "sns.heatmap(target_correlation, \n",
    "            annot=True, \n",
    "            cmap='coolwarm',\n",
    "            fmt='.3f')\n",
    "plt.title('Корреляция признаков с целевой переменной (is_canceled)', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Анализ важных признаков\n",
    "print(\"Признаки с наибольшей корреляцией с целевой переменной:\")\n",
    "top_correlations = full_correlation_matrix['is_canceled'].sort_values(ascending=False)\n",
    "print(top_correlations[1:16])\n",
    "\n",
    "# Визуализация топ коррелированных признаков\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_15 = top_correlations[1:16]\n",
    "sns.barplot(x=top_15.values, y=top_15.index, palette='viridis')\n",
    "plt.title('Топ-15 признаков по корреляции с целевой переменной')\n",
    "plt.xlabel('Коэффициент корреляции')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Шаг 3: Обработка пропущенных значений\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ШАГ 3: ОБРАБОТКА ПРОПУЩЕННЫХ ЗНАЧЕНИЙ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"Пропущенные значения до обработки:\")\n",
    "print(df_clean.isnull().sum().sort_values(ascending=False))\n",
    "\n",
    "# Заполнение пропущенных значений МЕДИАНОЙ для числовых колонок\n",
    "numerical_columns = df_clean.select_dtypes(include=[np.number]).columns\n",
    "categorical_columns = df_clean.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"\\nЗаполнение числовых колонок медианой:\")\n",
    "for col in numerical_columns:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        median_value = df_clean[col].median()\n",
    "        df_clean[col] = df_clean[col].fillna(median_value)\n",
    "        print(f\"Колонка {col}: заполнена медианой {median_value}\")\n",
    "\n",
    "# Заполнение категориальных колонок модой\n",
    "print(\"\\nЗаполнение категориальных колонок модой:\")\n",
    "for col in categorical_columns:\n",
    "    if df_clean[col].isnull().sum() > 0:\n",
    "        mode_value = df_clean[col].mode()[0] if not df_clean[col].mode().empty else 'Unknown'\n",
    "        df_clean[col] = df_clean[col].fillna(mode_value)\n",
    "        print(f\"Колонка {col}: заполнена значением '{mode_value}'\")\n",
    "\n",
    "print(f\"\\nРазмер датасета после обработки пропусков: {df_clean.shape}\")\n",
    "print(\"Пропущенные значения после обработки:\")\n",
    "print(df_clean.isnull().sum().sum())\n",
    "\n",
    "# Шаг 4: Обработка категориальных признаков\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ШАГ 4: ОБРАБОТКА КАТЕГОРИАЛЬНЫХ ПРИЗНАКОВ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Определение числовых и категориальных признаков для пайплайна\n",
    "numerical_features = df_clean.select_dtypes(include=[np.number]).columns.drop('is_canceled').tolist()\n",
    "categorical_features = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Числовые признаки ({len(numerical_features)}): {numerical_features}\")\n",
    "print(f\"Категориальные признаки ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "# Создание препроцессора (будет использоваться в пайплайнах)\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numerical_features),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "])\n",
    "\n",
    "print(\"Создан препроцессор для пайплайна\")\n",
    "\n",
    "# Шаг 5: Нормализация данных\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ШАГ 5: НОРМАЛИЗАЦИЯ ДАННЫХ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"Нормализация нужна для алгоритмов, чувствительных к масштабу (KNN, SVM)\")\n",
    "print(\"Нормализация будет выполнена внутри пайплайна с помощью StandardScaler\")\n",
    "\n",
    "# Шаг 6: Разбиение на обучающую и тестовую выборки\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ШАГ 6: РАЗБИЕНИЕ НА ОБУЧАЮЩУЮ И ТЕСТОВУЮ ВЫБОРКИ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "X = df_clean.drop('is_canceled', axis=1)\n",
    "y = df_clean['is_canceled']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")\n",
    "print(f\"Распределение классов в обучающей выборке:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Доля отмен в обучающей выборке: {y_train.mean():.2%}\")\n",
    "\n",
    "# Шаг 7: Запуск KNN классификатора\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ШАГ 7: ЗАПУСК KNN КЛАССИФИКАТОРА\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"Выбор KNN обоснован тем, что это простой интерпретируемый алгоритм,\")\n",
    "print(\"хорошо работающий на нормализованных данных\")\n",
    "\n",
    "knn_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "y_pred_knn = knn_pipe.predict(X_test)\n",
    "y_proba_knn = knn_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== KNN КЛАССИФИКАТОР ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba_knn):.4f}\")\n",
    "\n",
    "# Шаг 8: Подбор оптимального количества соседей\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ШАГ 8: ПОДБОР ОПТИМАЛЬНОГО КОЛИЧЕСТВА СОСЕДЕЙ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "param_grid = {'knn__n_neighbors': range(3, 21, 2)}\n",
    "knn_grid = GridSearchCV(knn_pipe, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "knn_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Лучший параметр: {knn_grid.best_params_}\")\n",
    "print(f\"Лучший ROC-AUC: {knn_grid.best_score_:.4f}\")\n",
    "\n",
    "# Визуализация подбора параметра\n",
    "plt.figure(figsize=(10, 6))\n",
    "results = knn_grid.cv_results_\n",
    "plt.plot(param_grid['knn__n_neighbors'], results['mean_test_score'], marker='o')\n",
    "plt.xlabel('Количество соседей')\n",
    "plt.ylabel('ROC-AUC Score')\n",
    "plt.title('Подбор оптимального количества соседей для KNN')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Шаг 9: Оценка лучшей модели KNN\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ШАГ 9: ОЦЕНКА ЛУЧШЕЙ МОДЕЛИ KNN\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_knn = knn_grid.best_estimator_\n",
    "y_train_pred_knn = best_knn.predict(X_train)\n",
    "y_test_pred_knn = best_knn.predict(X_test)\n",
    "\n",
    "print(\"=== ЛУЧШАЯ KNN МОДЕЛЬ ===\")\n",
    "print(f\"Обучающая выборка - Accuracy: {accuracy_score(y_train, y_train_pred_knn):.4f}\")\n",
    "print(f\"Тестовая выборка - Accuracy: {accuracy_score(y_test, y_test_pred_knn):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, best_knn.predict_proba(X_test)[:, 1]):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report для тестовой выборки:\")\n",
    "print(classification_report(y_test, y_test_pred_knn))\n",
    "\n",
    "# Шаг 10: Запуск других классификаторов\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ШАГ 10: СРАВНЕНИЕ С ДРУГИМИ КЛАССИФИКАТОРАМИ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Функция для оценки моделей\n",
    "def evaluate_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    start_time = pd.Timestamp.now()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    train_time = (pd.Timestamp.now() - start_time).total_seconds()\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Время обучения: {train_time:.2f} сек\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return {'accuracy': accuracy, 'roc_auc': roc_auc, 'model': model}\n",
    "\n",
    "# Создание и оценка моделей с пайплайнами\n",
    "models = {\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('lr', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n",
    "    ]),\n",
    "    'Random Forest': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('rf', RandomForestClassifier(n_estimators=150, class_weight='balanced', \n",
    "                                    random_state=42, n_jobs=-1))\n",
    "    ])\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    results[name] = evaluate_model(model, name, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Добавляем KNN в результаты\n",
    "results['KNN'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_test_pred_knn),\n",
    "    'roc_auc': roc_auc_score(y_test, best_knn.predict_proba(X_test)[:, 1]),\n",
    "    'model': best_knn\n",
    "}\n",
    "\n",
    "# Сравнение моделей\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[model]['accuracy'] for model in results],\n",
    "    'ROC-AUC': [results[model]['roc_auc'] for model in results]\n",
    "})\n",
    "\n",
    "print(\"\\n=== ИТОГОВОЕ СРАВНЕНИЕ МОДЕЛЕЙ ===\")\n",
    "print(comparison_df.sort_values('ROC-AUC', ascending=False))\n",
    "\n",
    "# Шаг 11: Борьба с несбалансированностью классов\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ШАГ 11: БОРЬБА С НЕСБАЛАНСИРОВАННОСТЬЮ КЛАССОВ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Распределение классов в обучающей выборке:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Доля положительного класса: {y_train.mean():.2%}\")\n",
    "\n",
    "# Применение SMOTE в пайплайне\n",
    "print(\"\\n=== ПРИМЕНЕНИЕ SMOTE ===\")\n",
    "\n",
    "smote_pipe = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "smote_pipe.fit(X_train, y_train)\n",
    "y_pred_smote = smote_pipe.predict(X_test)\n",
    "y_proba_smote = smote_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest + SMOTE:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_smote):.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba_smote):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_smote))\n",
    "\n",
    "# Сравнение с обычным Random Forest\n",
    "rf_original_acc = results['Random Forest']['accuracy']\n",
    "rf_original_auc = results['Random Forest']['roc_auc']\n",
    "rf_smote_acc = accuracy_score(y_test, y_pred_smote)\n",
    "rf_smote_auc = roc_auc_score(y_test, y_proba_smote)\n",
    "\n",
    "print(f\"\\nСравнение Random Forest до и после SMOTE:\")\n",
    "print(f\"Accuracy: {rf_original_acc:.4f} -> {rf_smote_acc:.4f} ({'+' if rf_smote_acc > rf_original_acc else ''}{rf_smote_acc - rf_original_acc:.4f})\")\n",
    "print(f\"ROC-AUC:  {rf_original_auc:.4f} -> {rf_smote_auc:.4f} ({'+' if rf_smote_auc > rf_original_auc else ''}{rf_smote_auc - rf_original_auc:.4f})\")\n",
    "\n",
    "# Шаг 12: Исключение коррелированных переменных\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ШАГ 12: ИСКЛЮЧЕНИЕ КОРРЕЛИРОВАННЫХ ПЕРЕМЕННЫХ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"Зачем исключать коррелированные переменные:\")\n",
    "print(\"1. Уменьшение мультиколлинеарности\")\n",
    "print(\"2. Улучшение интерпретируемости модели\") \n",
    "print(\"3. Сокращение времени обучения\")\n",
    "print(\"4. Уменьшение переобучения\")\n",
    "\n",
    "# Анализ корреляции между признаками\n",
    "print(\"\\nАнализ сильно коррелированных пар признаков (|corr| > 0.8):\")\n",
    "\n",
    "# Используем ранее созданную матрицу корреляции\n",
    "high_corr_pairs = []\n",
    "for i in range(len(full_correlation_matrix.columns)):\n",
    "    for j in range(i + 1, len(full_correlation_matrix.columns)):\n",
    "        if abs(full_correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            col1 = full_correlation_matrix.columns[i]\n",
    "            col2 = full_correlation_matrix.columns[j]\n",
    "            # Проверяем, что оба признака существуют в исходных данных\n",
    "            if col1 in df_clean.columns or any(col1.startswith(f\"{cat}_\") for cat in categorical_features):\n",
    "                if col2 in df_clean.columns or any(col2.startswith(f\"{cat}_\") for cat in categorical_features):\n",
    "                    high_corr_pairs.append((\n",
    "                        col1,\n",
    "                        col2,\n",
    "                        full_correlation_matrix.iloc[i, j]\n",
    "                    ))\n",
    "\n",
    "print(f\"Найдено {len(high_corr_pairs)} сильно коррелированных пар\")\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(\"Сильно коррелированные пары:\")\n",
    "    for pair in high_corr_pairs[:10]:  # Показываем первые 10\n",
    "        print(f\"  {pair[0]} - {pair[1]}: {pair[2]:.4f}\")\n",
    "else:\n",
    "    print(\"Сильно коррелированных пар не найдено\")\n",
    "\n",
    "# Шаг 13: Общие выводы\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ШАГ 13: ОБЩИЕ ВЫВОДЫ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Находим лучшую модель\n",
    "best_model_name = comparison_df.loc[comparison_df['ROC-AUC'].idxmax(), 'Model']\n",
    "best_accuracy = comparison_df.loc[comparison_df['ROC-AUC'].idxmax(), 'Accuracy']\n",
    "best_roc_auc = comparison_df.loc[comparison_df['ROC-AUC'].idxmax(), 'ROC-AUC']\n",
    "\n",
    "print(f\"\"\"\n",
    "1. КАЧЕСТВО МОДЕЛЕЙ:\n",
    "   - Лучшая модель: {best_model_name} (ROC-AUC: {best_roc_auc:.4f}, Accuracy: {best_accuracy:.4f})\n",
    "   - Random Forest показал стабильно высокие результаты\n",
    "   - KNN обеспечил хороший базовый уровень\n",
    "   - Все модели демонстрируют приемлемое качество\n",
    "\n",
    "2. ВАЖНЫЕ INSIGHTS:\n",
    "   - Наблюдается несбалансированность классов (~{y_train.mean():.1%} отмен)\n",
    "   - SMOTE улучшил предсказание minority class\n",
    "   - Найдено {len(high_corr_pairs)} сильно коррелированных пар признаков\n",
    "   - Признаки с наибольшей корреляцией с целевой переменной: {', '.join(top_correlations.index[1:4].tolist())}\n",
    "\n",
    "3. РЕКОМЕНДАЦИИ:\n",
    "   - Использовать {best_model_name} для production\n",
    "   - Регулярно переобучать модель на новых данных\n",
    "   - Мониторить важность признаков для бизнес-решений\n",
    "   - Рассмотреть feature engineering для улучшения качества\n",
    "\n",
    "4. БИЗНЕС-ПРИМЕНЕНИЕ:\n",
    "   - Прогнозирование загрузки отеля на основе вероятности отмен\n",
    "   - Разработка targeted-стратегий для групп риска\n",
    "   - Оптимизация управления доходами (revenue management)\n",
    "   - Улучшение клиентского сервиса\n",
    "\"\"\")\n",
    "\n",
    "# Визуализация важности признаков для лучшей модели\n",
    "if 'Random Forest' in results:\n",
    "    # Получаем имена признаков после преобразования\n",
    "    feature_names = (numerical_features + \n",
    "                    list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)))\n",
    "    \n",
    "    rf_model = results['Random Forest']['model']\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': rf_model.named_steps['rf'].feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nТоп-15 самых важных признаков (Random Forest):\")\n",
    "    print(feature_importance.head(15))\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
    "    plt.title('Топ-15 самых важных признаков (Random Forest)')\n",
    "    plt.xlabel('Важность')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Матрица ошибок для лучшей модели\n",
    "print(\"\\nМатрица ошибок для лучшей модели:\")\n",
    "best_model = results[best_model_name]['model']\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'Матрица ошибок ({best_model_name})')\n",
    "plt.ylabel('Истинные значения')\n",
    "plt.xlabel('Предсказанные значения')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
